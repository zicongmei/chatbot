
from causallm import run

model_name = "meta-llama/Llama-2-7b-chat-hf"

run(model_name=model_name)
